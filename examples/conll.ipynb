{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb156f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspaces/chisel/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783042a",
   "metadata": {},
   "source": [
    "# 🧪 Example: Processing CoNLL NER Data with Chisel\n",
    "This example demonstrates how to parse the CoNLL-2003 dataset into Chisel's internal ChiselRecord format, suitable for training transformer-based token classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b86656",
   "metadata": {},
   "source": [
    "## 📥 Step 1: Download CoNLL Data\n",
    "We use the version hosted by the [CrossWeigh](https://github.com/ZihanWangKi/CrossWeigh) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecdcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/ZihanWangKi/CrossWeigh/refs/heads/master/data/conllpp_train.txt\"\n",
    "response = requests.get(url)\n",
    "docs = response.text.split(\"-DOCSTART- -X- -X- O\\n\\n\")\n",
    "docs = list(filter(lambda x: len(x) > 0, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953a76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU NNP B-NP B-ORG\n",
      "rejects VBZ B-VP O\n",
      "German JJ B-NP B-MISC\n",
      "call NN I-NP O\n",
      "to TO B-VP O\n",
      "boycott VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Peter NNP B-NP B-PER\n",
      "Blackburn NNP I-NP I-PER\n",
      "\n",
      "BRUSSELS NNP B-NP B-LOC\n",
      "1996-08-22 CD I-NP O\n",
      "\n",
      "The DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Commission NNP I-NP I-ORG\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "Thursday NNP B-NP O\n",
      "it PRP B-NP O\n",
      "disagreed VBD B-VP O\n",
      "with IN B-PP O\n",
      "German JJ B-NP B-MISC\n",
      "advice NN I-NP O\n",
      "to TO B-PP O\n",
      "consumers NNS B-NP O\n",
      "to TO B-VP O\n",
      "shun VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      "until IN B-SBAR O\n",
      "scientists NNS B-NP O\n",
      "determine VBP B-VP O\n",
      "whether IN B-SBAR O\n",
      "mad JJ B-NP O\n",
      "cow NN I-NP O\n",
      "disease NN I-NP O\n",
      "can MD B-VP O\n",
      "be VB I-VP O\n",
      "transmitted VBN I-VP O\n",
      "to TO B-PP O\n",
      "sheep NN B-NP O\n",
      ". . O O\n",
      "\n",
      "Germany NNP B-NP B-LOC\n",
      "'s POS B-NP O\n",
      "representative NN I-NP O\n",
      "to TO B-PP O\n",
      "the DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Union NNP I-NP I-ORG\n",
      "'s POS B-NP O\n",
      "veterinary JJ I-NP O\n",
      "committee NN I-NP O\n",
      "Werner NNP I-NP B-PER\n",
      "Zwingmann NNP I-NP I-PER\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "Wednesday NNP B-NP O\n",
      "consumers NNS I-NP O\n",
      "should MD B-VP O\n",
      "buy VB I-VP O\n",
      "sheepmeat NN B-NP O\n",
      "from IN B-PP O\n",
      "countries NNS B-NP O\n",
      "other JJ B-ADJP O\n",
      "than IN B-PP O\n",
      "Britain NNP B-NP B-LOC\n",
      "until IN B-SBAR O\n",
      "the DT B-NP O\n",
      "scientific JJ I-NP O\n",
      "advice NN I-NP O\n",
      "was VBD B-VP O\n",
      "clearer JJR B-ADJP O\n",
      ". . O O\n",
      "\n",
      "\" \" O O\n",
      "We PRP B-NP O\n",
      "do VBP B-VP O\n",
      "n't RB I-VP O\n",
      "support VB I-VP O\n",
      "any DT B-NP O\n",
      "such JJ I-NP O\n",
      "recommendation NN I-NP O\n",
      "because IN B-SBAR O\n",
      "we PRP B-NP O\n",
      "do VBP B-VP O\n",
      "n't RB I-VP O\n",
      "see VB I-VP O\n",
      "any DT B-NP O\n",
      "grounds NNS I-NP O\n",
      "for IN B-PP O\n",
      "it PRP B-NP O\n",
      ", , O O\n",
      "\" \" O O\n",
      "the DT B-NP O\n",
      "Commission NNP I-NP B-ORG\n",
      "'s POS B-NP O\n",
      "chief JJ I-NP O\n",
      "spokesman NN I-NP O\n",
      "Nikolaus NNP I-NP B-PER\n",
      "van NNP I-NP I-PER\n",
      "der FW I-NP I-PER\n",
      "Pas NNP I-NP I-PER\n",
      "told VBD B-VP O\n",
      "a DT B-NP O\n",
      "news NN I-NP O\n",
      "briefing NN I-NP O\n",
      ". . O O\n",
      "\n",
      "He PRP B-NP O\n",
      "said VBD B-VP O\n",
      "further JJ B-NP O\n",
      "scientific JJ I-NP O\n",
      "study NN I-NP O\n",
      "was VBD B-VP O\n",
      "required VBN I-VP O\n",
      "and CC O O\n",
      "if IN B-SBAR O\n",
      "it PRP B-NP O\n",
      "was VBD B-VP O\n",
      "found VBN I-VP O\n",
      "that IN B-SBAR O\n",
      "action NN B-NP O\n",
      "was VBD B-VP O\n",
      "needed VBN I-VP O\n",
      "it PRP B-NP O\n",
      "should MD B-VP O\n",
      "be VB I-VP O\n",
      "taken VBN I-VP O\n",
      "by IN B-PP O\n",
      "the DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Union NNP I-NP I-ORG\n",
      ". . O O\n",
      "\n",
      "He PRP B-NP O\n",
      "said VBD B-VP O\n",
      "a DT B-NP O\n",
      "proposal NN I-NP O\n",
      "last JJ B-NP O\n",
      "month NN I-NP O\n",
      "by IN B-PP O\n",
      "EU NNP B-NP B-ORG\n",
      "Farm NNP I-NP O\n",
      "Commissioner NNP I-NP O\n",
      "Franz NNP I-NP B-PER\n",
      "Fischler NNP I-NP I-PER\n",
      "to TO B-VP O\n",
      "ban VB I-VP O\n",
      "sheep NN B-NP O\n",
      "brains NNS I-NP O\n",
      ", , O O\n",
      "spleens NNS B-NP O\n",
      "and CC O O\n",
      "spinal JJ B-NP O\n",
      "cords NNS I-NP O\n",
      "from IN B-PP O\n",
      "the DT B-NP O\n",
      "human NN I-NP O\n",
      "and CC I-NP O\n",
      "animal NN I-NP O\n",
      "food NN I-NP O\n",
      "chains NNS I-NP O\n",
      "was VBD B-VP O\n",
      "a DT B-NP O\n",
      "highly RB I-NP O\n",
      "specific JJ B-ADJP O\n",
      "and CC I-ADJP O\n",
      "precautionary JJ I-ADJP O\n",
      "move NN B-NP O\n",
      "to TO B-VP O\n",
      "protect VB I-VP O\n",
      "human JJ B-NP O\n",
      "health NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Fischler JJR B-NP B-PER\n",
      "proposed VBN I-NP O\n",
      "EU-wide NNP I-NP B-MISC\n",
      "measures VBZ B-VP O\n",
      "after IN B-PP O\n",
      "reports NNS B-NP O\n",
      "from IN B-PP O\n",
      "Britain NNP B-NP B-LOC\n",
      "and CC I-NP O\n",
      "France NNP I-NP B-LOC\n",
      "that WDT B-NP O\n",
      "under IN B-PP O\n",
      "laboratory NN B-NP O\n",
      "conditions NNS B-NP O\n",
      "sheep NN I-NP O\n",
      "could MD B-VP O\n",
      "contract VB I-VP O\n",
      "Bovine NNP B-NP B-MISC\n",
      "Spongiform NNP I-NP I-MISC\n",
      "Encephalopathy NNP I-NP I-MISC\n",
      "( ( O O\n",
      "BSE NNP B-NP B-MISC\n",
      ") ) O O\n",
      "-- : O O\n",
      "mad JJ B-NP O\n",
      "cow NN I-NP O\n",
      "disease NN I-NP O\n",
      ". . O O\n",
      "\n",
      "But CC O O\n",
      "Fischler NNP B-NP B-PER\n",
      "agreed VBD B-VP O\n",
      "to TO I-VP O\n",
      "review VB I-VP O\n",
      "his PRP$ B-NP O\n",
      "proposal NN I-NP O\n",
      "after IN B-PP O\n",
      "the DT B-NP O\n",
      "EU NNP I-NP B-ORG\n",
      "'s POS B-NP O\n",
      "standing NN I-NP O\n",
      "veterinary JJ I-NP O\n",
      "committee NN I-NP O\n",
      ", , O O\n",
      "mational JJ B-NP O\n",
      "animal NN I-NP O\n",
      "health NN I-NP O\n",
      "officials NNS I-NP O\n",
      ", , O O\n",
      "questioned VBD B-VP O\n",
      "if IN B-SBAR O\n",
      "such JJ B-NP O\n",
      "action NN I-NP O\n",
      "was VBD B-VP O\n",
      "justified VBN I-VP O\n",
      "as IN B-PP O\n",
      "there RB B-ADVP O\n",
      "was VBD B-VP O\n",
      "only RB B-ADVP O\n",
      "a DT B-NP O\n",
      "slight JJ I-NP O\n",
      "risk NN I-NP O\n",
      "to TO B-PP O\n",
      "human JJ B-NP O\n",
      "health NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Spanish NNP B-NP B-MISC\n",
      "Farm NNP I-NP O\n",
      "Minister NNP I-NP O\n",
      "Loyola NNP I-NP B-PER\n",
      "de NNP I-NP I-PER\n",
      "Palacio NNP I-NP I-PER\n",
      "had VBD B-VP O\n",
      "earlier RBR I-VP O\n",
      "accused VBN I-VP O\n",
      "Fischler NNP B-NP B-PER\n",
      "at IN B-PP O\n",
      "an DT B-NP O\n",
      "EU JJ I-NP B-ORG\n",
      "farm NN I-NP O\n",
      "ministers NNS I-NP O\n",
      "' POS B-NP O\n",
      "meeting NN I-NP O\n",
      "of IN B-PP O\n",
      "causing VBG B-VP O\n",
      "unjustified JJ B-ADJP O\n",
      "alarm NN B-NP O\n",
      "through IN B-PP O\n",
      "\" \" O O\n",
      "dangerous JJ B-NP O\n",
      "generalisation NN I-NP O\n",
      ". . O O\n",
      "\" \" O O\n",
      "\n",
      ". . O O\n",
      "\n",
      "Only RB B-NP O\n",
      "France NNP I-NP B-LOC\n",
      "and CC I-NP O\n",
      "Britain NNP I-NP B-LOC\n",
      "backed VBD B-VP O\n",
      "Fischler NNP B-NP B-PER\n",
      "'s POS B-NP O\n",
      "proposal NN I-NP O\n",
      ". . O O\n",
      "\n",
      "The DT B-NP O\n",
      "EU NNP I-NP B-ORG\n",
      "'s POS B-NP O\n",
      "scientific JJ I-NP O\n",
      "veterinary JJ I-NP O\n",
      "and CC I-NP O\n",
      "multidisciplinary JJ I-NP O\n",
      "committees NNS I-NP O\n",
      "are VBP B-VP O\n",
      "due JJ B-ADJP O\n",
      "to TO B-VP O\n",
      "re-examine VB I-VP O\n",
      "the DT B-NP O\n",
      "issue NN I-NP O\n",
      "early RB B-NP O\n",
      "next JJ I-NP O\n",
      "month NN I-NP O\n",
      "and CC O O\n",
      "make VB B-VP O\n",
      "recommendations NNS B-NP O\n",
      "to TO B-PP O\n",
      "the DT B-NP O\n",
      "senior JJ I-NP O\n",
      "veterinary JJ I-NP O\n",
      "officials NNS I-NP O\n",
      ". . O O\n",
      "\n",
      "Sheep NNP B-NP O\n",
      "have VBP B-VP O\n",
      "long RB I-VP O\n",
      "been VBN I-VP O\n",
      "known VBN I-VP O\n",
      "to TO B-PP O\n",
      "contract NN B-NP O\n",
      "scrapie NN I-NP O\n",
      ", , O O\n",
      "a DT B-NP O\n",
      "brain-wasting JJ I-NP O\n",
      "disease NN I-NP O\n",
      "similar JJ B-ADJP O\n",
      "to TO B-PP O\n",
      "BSE NNP B-NP B-MISC\n",
      "which WDT B-NP O\n",
      "is VBZ B-VP O\n",
      "believed VBN I-VP O\n",
      "to TO I-VP O\n",
      "have VB I-VP O\n",
      "been VBN I-VP O\n",
      "transferred VBN I-VP O\n",
      "to TO B-PP O\n",
      "cattle NNS B-NP O\n",
      "through IN B-PP O\n",
      "feed NN B-NP O\n",
      "containing VBG B-VP O\n",
      "animal NN B-NP O\n",
      "waste NN I-NP O\n",
      ". . O O\n",
      "\n",
      "British JJ B-NP B-MISC\n",
      "farmers NNS I-NP O\n",
      "denied VBN B-VP O\n",
      "on IN B-PP O\n",
      "Thursday NNP B-NP O\n",
      "there EX B-NP O\n",
      "was VBD B-VP O\n",
      "any DT B-NP O\n",
      "danger NN I-NP O\n",
      "to TO B-PP O\n",
      "human JJ B-NP O\n",
      "health NN I-NP O\n",
      "from IN B-PP O\n",
      "their PRP$ B-NP O\n",
      "sheep NN I-NP O\n",
      ", , O O\n",
      "but CC O O\n",
      "expressed VBD B-VP O\n",
      "concern NN B-NP O\n",
      "that IN B-SBAR O\n",
      "German JJ B-NP B-MISC\n",
      "government NN I-NP O\n",
      "advice NN I-NP O\n",
      "to TO B-PP O\n",
      "consumers NNS B-NP O\n",
      "to TO B-VP O\n",
      "avoid VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      "might MD B-VP O\n",
      "influence VB I-VP O\n",
      "consumers NNS B-NP O\n",
      "across IN B-PP O\n",
      "Europe NNP B-NP B-LOC\n",
      ". . O O\n",
      "\n",
      "\" \" O O\n",
      "What WP B-NP O\n",
      "we PRP B-NP O\n",
      "have VBP B-VP O\n",
      "to TO I-VP O\n",
      "be VB I-VP O\n",
      "extremely RB B-ADJP O\n",
      "careful JJ I-ADJP O\n",
      "of IN B-PP O\n",
      "is VBZ B-VP O\n",
      "how WRB B-ADVP O\n",
      "other JJ B-NP O\n",
      "countries NNS I-NP O\n",
      "are VBP B-VP O\n",
      "going VBG I-VP O\n",
      "to TO I-VP O\n",
      "take VB I-VP O\n",
      "Germany NNP B-NP B-LOC\n",
      "'s POS B-NP O\n",
      "lead NN I-NP O\n",
      ", , O O\n",
      "\" \" O O\n",
      "Welsh NNP B-NP B-ORG\n",
      "National NNP I-NP I-ORG\n",
      "Farmers NNP I-NP I-ORG\n",
      "' POS B-NP I-ORG\n",
      "Union NNP I-NP I-ORG\n",
      "( ( O O\n",
      "NFU NNP B-NP B-ORG\n",
      ") ) O O\n",
      "chairman NN B-NP O\n",
      "John NNP I-NP B-PER\n",
      "Lloyd NNP I-NP I-PER\n",
      "Jones NNP I-NP I-PER\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "BBC NNP B-NP B-ORG\n",
      "radio NN I-NP I-ORG\n",
      ". . O O\n",
      "\n",
      "Bonn NNP B-NP B-LOC\n",
      "has VBZ B-VP O\n",
      "led VBN I-VP O\n",
      "efforts NNS B-NP O\n",
      "to TO B-VP O\n",
      "protect VB I-VP O\n",
      "public JJ B-NP O\n",
      "health NN I-NP O\n",
      "after IN B-PP O\n",
      "consumer NN B-NP O\n",
      "confidence NN I-NP O\n",
      "collapsed VBD B-VP O\n",
      "in IN B-PP O\n",
      "March NNP B-NP O\n",
      "after IN B-PP O\n",
      "a DT B-NP O\n",
      "British JJ I-NP B-MISC\n",
      "report NN I-NP O\n",
      "suggested VBD B-VP O\n",
      "humans NNS B-NP O\n",
      "could MD B-VP O\n",
      "contract VB I-VP O\n",
      "an DT B-NP O\n",
      "illness NN I-NP O\n",
      "similar JJ B-ADJP O\n",
      "to TO I-ADJP O\n",
      "mad JJ I-ADJP O\n",
      "cow NN B-NP O\n",
      "disease NN I-NP O\n",
      "by IN B-PP O\n",
      "eating VBG B-VP O\n",
      "contaminated VBN I-VP O\n",
      "beef NN B-NP O\n",
      ". . O O\n",
      "\n",
      "Germany NNP B-NP B-LOC\n",
      "imported VBD B-VP O\n",
      "47,600 CD B-NP O\n",
      "sheep NN I-NP O\n",
      "from IN B-PP O\n",
      "Britain NNP B-NP B-LOC\n",
      "last JJ B-NP O\n",
      "year NN I-NP O\n",
      ", , O O\n",
      "nearly RB B-NP O\n",
      "half NN I-NP O\n",
      "of IN B-PP O\n",
      "total JJ B-NP O\n",
      "imports NNS I-NP O\n",
      ". . O O\n",
      "\n",
      "It PRP B-NP O\n",
      "brought VBD B-VP O\n",
      "in IN B-PP O\n",
      "4,275 CD B-NP O\n",
      "tonnes NNS I-NP O\n",
      "of IN B-PP O\n",
      "British JJ B-NP B-MISC\n",
      "mutton NN I-NP O\n",
      ", , O O\n",
      "some DT B-NP O\n",
      "10 CD I-NP O\n",
      "percent NN I-NP O\n",
      "of IN B-PP O\n",
      "overall JJ B-NP O\n",
      "imports NNS I-NP O\n",
      ". . O O\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in docs[0:1]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c4a56",
   "metadata": {},
   "source": [
    "## 🧩 Step 2: Define a Parser for CoNLL Format\n",
    "Note: Whilst this may seem a bit complicated at first glance, with help of generative AI and the validators chisel provide, it should be fairly quick to write own custom parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8995a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from chisel.extraction.base.protocols import Parser\n",
    "from chisel.extraction.models.models import EntitySpan\n",
    "import string\n",
    "\n",
    "\n",
    "class ConllParser(Parser):\n",
    "    def parse(self, doc: str) -> Tuple[str, List[EntitySpan]]:\n",
    "        tokens, labels = [], []\n",
    "        for line in doc.strip().splitlines():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            splits = line.strip().split(\" \")\n",
    "            tokens.append(splits[0])\n",
    "            labels.append(splits[-1])\n",
    "\n",
    "        text = \"\"\n",
    "        spans = []\n",
    "        char_offset = 0\n",
    "        i = 0\n",
    "\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            label = labels[i]\n",
    "\n",
    "            # Only add joiner if previous token exists and current token is not punctuation\n",
    "            if text and token not in string.punctuation:\n",
    "                text += \" \"\n",
    "                char_offset += len(\" \")\n",
    "\n",
    "            if label.startswith(\"B-\"):\n",
    "                ent_label = label[2:]\n",
    "                ent_start = char_offset\n",
    "                ent_text = token\n",
    "                text += token\n",
    "                char_offset += len(token)\n",
    "                i += 1\n",
    "                while i < len(tokens) and labels[i].startswith(\"I-\"):\n",
    "                    text += \" \" + tokens[i]\n",
    "                    ent_text += \" \" + tokens[i]\n",
    "                    char_offset += len(\" \") + len(tokens[i])\n",
    "                    i += 1\n",
    "                ent_end = char_offset\n",
    "                spans.append(\n",
    "                    EntitySpan(\n",
    "                        text=ent_text, start=ent_start, end=ent_end, label=ent_label\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                text += token\n",
    "                char_offset += len(token)\n",
    "                i += 1\n",
    "        return text.strip(), spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8812b",
   "metadata": {},
   "source": [
    "## 🔧 Step 3: Initialize Chisel Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64396e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 📦 Imports\n",
    "from transformers import AutoTokenizer\n",
    "from chisel.extraction.tokenizers.hf_tokenizer import HFTokenizer\n",
    "from chisel.extraction.span_aligners.token_span_aligner import TokenSpanAligner\n",
    "from chisel.extraction.labelers.bio_labeler import BIOLabeler\n",
    "from chisel.extraction.labelers.label_encoder import SimpleLabelEncoder\n",
    "from chisel.extraction.validators.validators import DefaultParseValidator, HFTokenAlignmentValidator\n",
    "from chisel.extraction.formatters.hf_formatter import HFDatasetFormatter\n",
    "from chisel.extraction.models.models import ChiselRecord\n",
    "from chisel.extraction.models.models import EntitySpan\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f945d",
   "metadata": {},
   "source": [
    "## 📦 Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e48d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ConllParser()\n",
    "tokenizer = HFTokenizer(model_name=\"bert-base-cased\")\n",
    "aligner = TokenSpanAligner()\n",
    "labeler = BIOLabeler()\n",
    "label_encoder = SimpleLabelEncoder(label_to_id={\n",
    " 'O': 0,\n",
    " 'B-ORG': 1,\n",
    " 'I-ORG': 2,\n",
    " 'B-PER': 3,\n",
    " 'I-PER': 4,\n",
    " 'B-MISC': 5,\n",
    " 'I-MISC': 6,\n",
    " 'B-LOC': 7,\n",
    " 'I-LOC': 8\n",
    "})\n",
    "\n",
    "parse_validators = [DefaultParseValidator()]\n",
    "label_validators = [HFTokenAlignmentValidator(tokenizer=tokenizer.tokenizer)]\n",
    "formatters = HFDatasetFormatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803c8d5",
   "metadata": {},
   "source": [
    "## 🔄 Step 4: Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1393f674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "# 🔁 Pipeline loop\n",
    "for idx, example in enumerate(docs):\n",
    "    text, entities = parser.parse(example)\n",
    "    \n",
    "    # 🧪 Per-span validation — skip bad spans\n",
    "    valid_spans = []\n",
    "    for span in entities:\n",
    "        try:\n",
    "            for validator in parse_validators:\n",
    "                validator.validate(text, span)\n",
    "            valid_spans.append(span)\n",
    "        except ValueError:\n",
    "            continue \n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_entity_spans = aligner.align(entities, tokens)\n",
    "\n",
    "    labels = labeler.label(tokens, token_entity_spans)\n",
    "    encoded_labels = label_encoder.encode(labels)\n",
    "\n",
    "    # 🧪 Per-span validation — skip bad spans\n",
    "    valid_token_spans = []\n",
    "    for span in token_entity_spans:\n",
    "        try:\n",
    "            for validator in label_validators:\n",
    "                validator.validate(tokens, span)\n",
    "            valid_token_spans.append(span)\n",
    "        except ValueError:\n",
    "            continue  # Optionally log or collect stats on dropped spans\n",
    "\n",
    "    record = ChiselRecord(\n",
    "                id=str(idx),\n",
    "                chunk_id=0,\n",
    "                text=tokenizer.tokenizer.decode([token.id for token in tokens]),\n",
    "                tokens=tokens,\n",
    "                input_ids=[token.id for token in tokens],\n",
    "                attention_mask=[1] * len(tokens),\n",
    "                entities=[tes.entity for tes in valid_token_spans],\n",
    "                bio_labels=labels,\n",
    "                labels=encoded_labels\n",
    "            )\n",
    "    processed_data.append(record)\n",
    "\n",
    "data = formatters.format(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cc7b6",
   "metadata": {},
   "source": [
    "### ✅ Output\n",
    "You now have a model ready hugginface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3000c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'chunk_id', 'tokens', 'input_ids', 'attention_mask', 'labels', 'bio_labels'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ecbb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token (7270): EU, 1, B-ORG\n",
      "Token (22961): rejects, 0, O\n",
      "Token (1528): German, 5, B-MISC\n",
      "Token (1840): call, 0, O\n",
      "Token (1106): to, 0, O\n",
      "Token (21423): boycott, 0, O\n",
      "Token (1418): British, 5, B-MISC\n",
      "Token (2495): la, 0, O\n",
      "Token (12913): ##mb, 0, O\n",
      "Token (119): ., 0, O\n"
     ]
    }
   ],
   "source": [
    "for token, idx, label, bio_label in zip(\n",
    "    data[0][\"tokens\"][0:10],\n",
    "    data[0][\"input_ids\"][0:10], \n",
    "    data[0][\"labels\"][0:10], \n",
    "    data[0][\"bio_labels\"][0:10]\n",
    "):\n",
    "    print(f\"Token ({idx}): {token}, {label}, {bio_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
