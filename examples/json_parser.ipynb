{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e944ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1235/1235 [00:00<00:00, 25938.09 examples/s]\n",
      "Generating eval split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 70010.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"explosion/ner-fashion-brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7d8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspaces/chisel/\")\n",
    "\n",
    "from chisel.extraction.parsers.json_span_parser import JSONSpanParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9abd334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Imports\n",
    "from typing import Tuple, List\n",
    "from chisel.extraction.base.protocols import Parser\n",
    "from chisel.extraction.models.models import EntitySpan\n",
    "from transformers import AutoTokenizer\n",
    "from chisel.extraction.tokenizers.hf_tokenizer import HFTokenizer\n",
    "from chisel.extraction.span_aligners.token_span_aligner import TokenSpanAligner\n",
    "from chisel.extraction.labelers.bilo_labeler import BILOLabeler\n",
    "from chisel.extraction.labelers.label_encoder import SimpleLabelEncoder\n",
    "from chisel.extraction.validators.validators import DefaultParseValidator, HFTokenAlignmentValidator\n",
    "from chisel.extraction.exporters.dataset_exporter import DatasetExporter\n",
    "from chisel.extraction.models.models import ChiselRecord\n",
    "from chisel.extraction.models.models import EntitySpan\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45fb80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONSpanParser(Parser):\n",
    "    def parse(self, doc: str) -> Tuple[str, List[EntitySpan]]:\n",
    "        \"\"\"\n",
    "        Parse a JSON-formatted string into plain text and entity spans.\n",
    "\n",
    "        The input JSON must contain:\n",
    "        - \"text\": a string of the original text\n",
    "        - \"entities\": a list of dicts with \"start\", \"end\", and \"label\"\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        doc : str\n",
    "            A JSON string representing a single document with character-level entity annotations.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        Tuple[str, List[EntitySpan]]\n",
    "            The original text and a list of extracted entity spans.\n",
    "        \"\"\"\n",
    "        text = doc[\"text\"]\n",
    "        entities = [\n",
    "            EntitySpan(\n",
    "                text=text[e[\"start\"] : e[\"end\"]],\n",
    "                start=e[\"start\"],\n",
    "                end=e[\"end\"],\n",
    "                label=e[\"label\"],\n",
    "            )\n",
    "            for e in doc.get(\"spans\", [])\n",
    "        ]\n",
    "        return text, entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Components\n",
    "parser = JSONSpanParser()\n",
    "tokenizer = HFTokenizer(model_name=\"bert-base-cased\")\n",
    "aligner = TokenSpanAligner()\n",
    "labeler = BILOLabeler()\n",
    "label_encoder = SimpleLabelEncoder(label_to_id={\n",
    " 'O': 0,\n",
    " 'B-FASHION_BRAND': 1,\n",
    " 'I-FASHION_BRAND': 2,\n",
    " 'L-FASHION_BRAND': 3,\n",
    " 'U-FASHION_BRAND': 4,\n",
    "})\n",
    "\n",
    "parse_validators = [DefaultParseValidator()]\n",
    "label_validators = [HFTokenAlignmentValidator(tokenizer=tokenizer.tokenizer)]\n",
    "\n",
    "\n",
    "exporter = DatasetExporter(output_path=\"./data/fashion-brands-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df01534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1235/1235 [00:00<00:00, 9064.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Export complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "# ðŸ” Pipeline loop\n",
    "for idx, example in enumerate(ds[\"train\"]):\n",
    "    text, entities = parser.parse(example)\n",
    "    \n",
    "    for validator in parse_validators:\n",
    "        validator.validate(text, entities)\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_entity_spans = aligner.align(entities, tokens)\n",
    "\n",
    "    labels = labeler.label(tokens, token_entity_spans)\n",
    "    encoded_labels = label_encoder.encode(labels)\n",
    "\n",
    "    for validator in label_validators:\n",
    "        validator.validate(tokens, token_entity_spans)\n",
    "\n",
    "    record = ChiselRecord(\n",
    "                id=str(idx),\n",
    "                chunk_id=0,\n",
    "                text=tokenizer.tokenizer.decode([token.id for token in tokens]),\n",
    "                tokens=tokens,\n",
    "                input_ids=[token.id for token in tokens],\n",
    "                attention_mask=[1] * len(tokens),\n",
    "                entities=[tes.entity for tes in token_entity_spans],\n",
    "                bio_labels=labels,\n",
    "                labels=encoded_labels\n",
    "            )\n",
    "    processed_data.append(record)\n",
    "\n",
    "# export\n",
    "exporter.export(processed_data)\n",
    "print(\"âœ… Export complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0fe91",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './data/fashion-brands-ner.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/fashion-brands-ner.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     d = pickle.load( f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: './data/fashion-brands-ner.pkl'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
