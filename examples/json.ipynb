{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e944ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspaces/chisel/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45cfd0a",
   "metadata": {},
   "source": [
    "# ðŸ‘— Example: Processing Fashion Brand NER (JSON Format) with Chisel\n",
    "\n",
    "This example shows how to preprocess the explosion/ner-fashion-brands dataset into ChiselRecord objects for training transformer-based NER models using BILO labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7bcd1",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7d8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the latest cached version of the dataset since explosion/ner-fashion-brands couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/vscode/.cache/huggingface/datasets/explosion___ner-fashion-brands/default/0.0.0/3e49f04a58c644035071317efa1c3d6e4a52e6e6 (last modified on Mon Jun  9 06:26:22 2025).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"explosion/ner-fashion-brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a229a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'meta', '_input_hash', '_task_hash', 'tokens', 'spans', '_session_id', '_view_id', 'answer'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b2c09",
   "metadata": {},
   "source": [
    "## ðŸ§© Step 2: Implement a JSON Span Parser\n",
    "The dataset provides character-level spans in a spans field. We write a parser that extracts these into Chisel's EntitySpan format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f17605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from chisel.extraction.base.protocols import Parser\n",
    "from chisel.extraction.models.models import EntitySpan\n",
    "\n",
    "class JSONSpanParser(Parser):\n",
    "    def parse(self, doc: dict) -> Tuple[str, List[EntitySpan]]:\n",
    "        text = doc[\"text\"]\n",
    "        entities = [\n",
    "            EntitySpan(\n",
    "                text=text[e[\"start\"]:e[\"end\"]],\n",
    "                start=e[\"start\"],\n",
    "                end=e[\"end\"],\n",
    "                label=e[\"label\"]\n",
    "            )\n",
    "            for e in doc.get(\"spans\", [])\n",
    "        ]\n",
    "        return text, entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eea4b3",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 3: Initialize Chisel Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717023e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chisel.extraction.tokenizers.hf_tokenizer import HFTokenizer\n",
    "from chisel.extraction.span_aligners.token_span_aligner import TokenSpanAligner\n",
    "from chisel.extraction.labelers.bilo_labeler import BILOLabeler\n",
    "from chisel.extraction.labelers.label_encoder import SimpleLabelEncoder\n",
    "from chisel.extraction.validators.validators import DefaultParseValidator, HFTokenAlignmentValidator\n",
    "from chisel.extraction.formatters.torch_formatter import TorchDatasetFormatter\n",
    "from chisel.extraction.models.models import ChiselRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b40a9a",
   "metadata": {},
   "source": [
    "## Component Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f1ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JSONSpanParser()\n",
    "tokenizer = HFTokenizer(model_name=\"bert-base-cased\")\n",
    "aligner = TokenSpanAligner()\n",
    "labeler = BILOLabeler()\n",
    "\n",
    "label_encoder = SimpleLabelEncoder(label_to_id={\n",
    "    'O': 0,\n",
    "    'B-FASHION_BRAND': 1,\n",
    "    'I-FASHION_BRAND': 2,\n",
    "    'L-FASHION_BRAND': 3,\n",
    "    'U-FASHION_BRAND': 4,\n",
    "})\n",
    "\n",
    "parse_validators = [DefaultParseValidator()]\n",
    "label_validators = [HFTokenAlignmentValidator(tokenizer=tokenizer.tokenizer)]\n",
    "formatter = TorchDatasetFormatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e801e30",
   "metadata": {},
   "source": [
    "## ðŸ”„ Step 4: Run the Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0be6b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "processed_data = []\n",
    "\n",
    "for idx, example in enumerate(ds[\"train\"]):\n",
    "    text, entities = parser.parse(example)\n",
    "\n",
    "    for validator in parse_validators:\n",
    "        validator.validate(text, entities)\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_entity_spans = aligner.align(entities, tokens)\n",
    "\n",
    "    labels = labeler.label(tokens, token_entity_spans)\n",
    "    encoded_labels = label_encoder.encode(labels)\n",
    "\n",
    "    for validator in label_validators:\n",
    "        validator.validate(tokens, token_entity_spans)\n",
    "\n",
    "    record = ChiselRecord(\n",
    "        id=str(idx),\n",
    "        chunk_id=0,\n",
    "        text=tokenizer.tokenizer.decode([token.id for token in tokens]),\n",
    "        tokens=tokens,\n",
    "        input_ids=[token.id for token in tokens],\n",
    "        attention_mask=[1] * len(tokens),\n",
    "        entities=[tes.entity for tes in token_entity_spans],\n",
    "        bio_labels=labels,\n",
    "        labels=encoded_labels\n",
    "    )\n",
    "    processed_data.append(record)\n",
    "\n",
    "data = formatter.format(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3727a8",
   "metadata": {},
   "source": [
    "### âœ… Output\n",
    "You now have a torch dataset ready for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1d4338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 1135,   112,   188,  1155, 12629,  1111,  1134,  2736,  1618,   117,\n",
       "          7572,   146,  1631,  1115,  1103,  1167,  2379,  1103,  1716,  2736,\n",
       "          1103,  1618,  1103,  1947,   117,  1134,  1111,  1143,  2086,  1280,\n",
       "          1114,   170, 22591,  1566,  3146,  1134,  2972,  1103,  1716,  1702,\n",
       "          1112,  2379,  1112,  1936,  1229,  1253,  2355,  1122,  1107,  1282]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
